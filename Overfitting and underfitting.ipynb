{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias \n",
    "Varience\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Overfitting occurs when our ML model tries to cover all the data points or more than required data points from the dataset.\n",
    "Training data accuracy >> 95%\n",
    "Testing data accuracy  >> 70%\n",
    "There is a lot difference in between training and testing data accuracy."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bias:\n",
    "    It is only about the training data, when we discuss about overfitting and underfitting concepts or issue.\n",
    "    If bias is very low, then training data accuracy is high >> 90-95%\n",
    "    If bias is high, then training data accuracy is low >>  70-80%\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Varience:\n",
    "    It is difference between the accuracies of two different datasets.\n",
    "    Two different datasets are nothing but training and testing datasets.\n",
    "    \n",
    "High Varience : High difference in between accuracies of training and testing datasets.\n",
    "    \n",
    "Low Varience: Low/less difference in between accuracies of training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. High training data accuracy and low testing data accuracy >> Overfitting\n",
    "   Low Bias and High Varience\n",
    "\n",
    "2. Low Training data accuracy and High testing data Accuracy >> Practically not possible.\n",
    "\n",
    "3. Low training data accuracy and low testing data accuracy >> Underfitting\n",
    "   High Bias and Low Varience \n",
    "\n",
    "4. High training data accuracy and High testing data accuracy >> Best Model\n",
    "   Low Bias and Low Varience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Overfitting occurs when our ML model tries to cover all the data points or more than required data points from the dataset.\n",
    "Training data accuracy >> 95%\n",
    "Testing data accuracy  >> 70%\n",
    "\n",
    "Model does perform well only on training dataset.\n",
    "There is a lot difference in between training and testing data accuracy.\n",
    "Low Bias and High Varience.\n",
    "\n",
    "Training data accuracy >> 95%(Regression), >> 97%(Classification)\n",
    "Testing data accuracy  >> 70%(Regression), >> 70-75%(Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underfitting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It occurs when our model is not able to cover/capture the trend of data.\n",
    "\n",
    "Training data accuracy >> 75%\n",
    "Testing data accuracy >> 70%\n",
    "\n",
    "Model is neither perform well on training dataset nor on testing dataset.\n",
    "High Bias and Low Varience\n",
    "\n",
    "Training data accuracy >> 55%(Regression), >> 70%(Classification)\n",
    "Testing data accuracy  >> 58%(Regression), >> 68%(Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model is performing well on training dataset as well as testing dataset.\n",
    "\n",
    "Training data accuracy >> 95%(Regression), >> 97%(Classification)\n",
    "Testing data accuracy  >> 92%(Regression), >> 95%(Classification)\n",
    "\n",
    "Low Bias and Low Varience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Low Bias and High Varience >> Overfitting\n",
    "High Bias and Low Varience >> Underffiting\n",
    "Low Bias and Low Varience  >> Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Handle/Avoid Overfitting Issue"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Hyperparameter Tunning:\n",
    "   Parameters which define the model architecture are referred to as hyper parameter. And the process of searching the best parameters for ideal model or best model building is nothing but Hyper-parameter tunning.\n",
    "   a. GridSearchCV\n",
    "   b. RandomizedSearchCV\n",
    "   \n",
    "2. Train with more data (no. of observations(no. of rows) should be as much as possible.)\n",
    "\n",
    "3. Reduce No. of features(30 >> 15, features/variables)\n",
    "   Feature Selection Techniques\n",
    "   Dimensionality Reduction Technique( PCA, LDA )\n",
    "   \n",
    "4. Prunning( Cutting Branches of the Decision Tree) >> Tree Based Model\n",
    "\n",
    "5. Regularization(L1 and L2) : Only used in linear Model (Linear Regression and Logistic Regression)\n",
    "   a. L1 Regularization >> Lasso Regression\n",
    "   b. L2 Regularization >> Ridge Regression\n",
    "   \n",
    "6. Cross Validation:\n",
    "    K-fold cross validation\n",
    "    \n",
    "7. Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to handle/avoid Underfitting Issue"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Increase the no. of features\n",
    "   10 >> 15\n",
    "   adding new variables\n",
    "   add derived features(creating multiple features from single feature.)\n",
    "    \n",
    "2. use Proper Feature Selection:\n",
    "    1. Filter Method\n",
    "    2. Wrapper Method\n",
    "    3. Embedded Method\n",
    "    \n",
    "3. Hyper-parameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier( criterion=['gini','entropy']\n",
    "                        max_depth=None,\n",
    "                        min_samples_split=(2,20),\n",
    "                        min_samples_leaf=(1,5))\n",
    "\n",
    "1. ID3 >> Iterative Decomiser 3 >> Entropy\n",
    "2. CART >> Classification and Regression Tree >> gini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
